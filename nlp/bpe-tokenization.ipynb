{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenization\n",
        "\n",
        "- Why can't LLM spell words? Tokenization.\n",
        "- Why can't LLM do super simple string processing tasks like reversing a string? Tokenization.\n",
        "- Why is LLM worse at non-English languages (e.g. Japanese)? Tokenization.\n",
        "- Why is LLM bad at simple arithmetic? Tokenization.\n",
        "- Why did GPT-2 have more than necessary trouble coding in Python? Tokenization.\n",
        "- Why did my LLM abruptly halt when it sees the string \"<|endoftext|>\"? Tokenization.\n",
        "- What is this weird warning I get about a \"trailing whitespace\"? Tokenization.\n",
        "- Why the LLM break if I ask it about \"SolidGoldMagikarp\"? Tokenization\n",
        "- Why should I prefer to use YAML over JSON with LLMs? Tokenization.\n",
        "- Why is LLM not actually end-to-end language modeling? Tokenization.\n",
        "- What is the real root of suffering? Tokenization."
      ],
      "metadata": {
        "id": "xetZYtW6GG3D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "sRaoGCJuE5_d",
        "outputId": "6777245c-4191-48a8-97e8-c3fb96eb249c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hola en otro idioma!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "\"Hola en otro idioma!\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ord(\"h\") # -> Gives the Unicode point"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhCd9aYZLlo8",
        "outputId": "9734492e-6c82-4348-ae77-bfb27d65daa0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "104"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[ord(x) for x in \"Hola en otro idioma!\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJTqU_dBMEl9",
        "outputId": "53af1fe9-98f0-484f-b5cd-fae64d1b299a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[72,\n",
              " 111,\n",
              " 108,\n",
              " 97,\n",
              " 32,\n",
              " 101,\n",
              " 110,\n",
              " 32,\n",
              " 111,\n",
              " 116,\n",
              " 114,\n",
              " 111,\n",
              " 32,\n",
              " 105,\n",
              " 100,\n",
              " 105,\n",
              " 111,\n",
              " 109,\n",
              " 97,\n",
              " 33]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list(\"Hola en otro idioma!\".encode(\"utf-8\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZoRow2QfSxU",
        "outputId": "80ce528f-a8fd-4ead-af4f-de9a54ff458f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[72,\n",
              " 111,\n",
              " 108,\n",
              " 97,\n",
              " 32,\n",
              " 101,\n",
              " 110,\n",
              " 32,\n",
              " 111,\n",
              " 116,\n",
              " 114,\n",
              " 111,\n",
              " 32,\n",
              " 105,\n",
              " 100,\n",
              " 105,\n",
              " 111,\n",
              " 109,\n",
              " 97,\n",
              " 33]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Byte Pair encoding\n",
        "\n",
        "Encoding strings of text into tabular form for use in downstream modeling.\n",
        "Suppose the data to be encoded is:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "aaabdaaabac\n",
        "```\n",
        "\n",
        "The byte pair \"aa\" occurs most often, so it will be replaced by a byte that is not used in the data, such as \"Z\". Now there is the following data and replacement table:\n",
        "\n",
        "```\n",
        "ZabdZabac\n",
        "Z=aa\n",
        "```\n",
        "\n",
        "Then the process is repeated with byte pair \"ab\", replacing it with \"Y\":\n",
        "\n",
        "```\n",
        "ZYdZYac\n",
        "Y=ab\n",
        "Z=aa\n",
        "```\n",
        "\n",
        "The only literal byte pair left occurs only once, and the encoding might stop here. Alternatively, the process could continue with recursive byte pair encoding, replacing \"ZY\" with \"X\":\n",
        "\n",
        "```\n",
        "XdXac\n",
        "X=ZY\n",
        "Y=ab\n",
        "Z=aa\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "N9sY3vzuhBsI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text=\"Byte-Pair Encoding (BPE) was initially developed as an algorithm to compress texts, and then used by OpenAI for tokenization when pretraining the GPT model. Itâ€™s used by a lot of Transformer models, including GPT, GPT-2, RoBERTa, BART, and DeBERTa.\"\n",
        "tokens = text.encode(\"utf-8\")\n",
        "tokens= list(map(int,tokens))\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2g1BauSAZyR6",
        "outputId": "4923aaae-23b0-4920-80d6-c45278d6122f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[66, 121, 116, 101, 45, 80, 97, 105, 114, 32, 69, 110, 99, 111, 100, 105, 110, 103, 32, 40, 66, 80, 69, 41, 32, 119, 97, 115, 32, 105, 110, 105, 116, 105, 97, 108, 108, 121, 32, 100, 101, 118, 101, 108, 111, 112, 101, 100, 32, 97, 115, 32, 97, 110, 32, 97, 108, 103, 111, 114, 105, 116, 104, 109, 32, 116, 111, 32, 99, 111, 109, 112, 114, 101, 115, 115, 32, 116, 101, 120, 116, 115, 44, 32, 97, 110, 100, 32, 116, 104, 101, 110, 32, 117, 115, 101, 100, 32, 98, 121, 32, 79, 112, 101, 110, 65, 73, 32, 102, 111, 114, 32, 116, 111, 107, 101, 110, 105, 122, 97, 116, 105, 111, 110, 32, 119, 104, 101, 110, 32, 112, 114, 101, 116, 114, 97, 105, 110, 105, 110, 103, 32, 116, 104, 101, 32, 71, 80, 84, 32, 109, 111, 100, 101, 108, 46, 32, 73, 116, 226, 128, 153, 115, 32, 117, 115, 101, 100, 32, 98, 121, 32, 97, 32, 108, 111, 116, 32, 111, 102, 32, 84, 114, 97, 110, 115, 102, 111, 114, 109, 101, 114, 32, 109, 111, 100, 101, 108, 115, 44, 32, 105, 110, 99, 108, 117, 100, 105, 110, 103, 32, 71, 80, 84, 44, 32, 71, 80, 84, 45, 50, 44, 32, 82, 111, 66, 69, 82, 84, 97, 44, 32, 66, 65, 82, 84, 44, 32, 97, 110, 100, 32, 68, 101, 66, 69, 82, 84, 97, 46]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Byte Pair Encoding\n",
        "def get_stats(ids):\n",
        "  counts = {}\n",
        "  for pair in zip(ids,ids[1:]): # Iterate over consecutive elements\n",
        "    counts[pair]= counts.get(pair,0)+1\n",
        "  return counts\n",
        "\n",
        "stats= get_stats(tokens)\n",
        "print(stats)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6wmEm8bahW5",
        "outputId": "b99961b4-b87d-4dbd-b74b-5f8b060c3666"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{(66, 121): 1, (121, 116): 1, (116, 101): 2, (101, 45): 1, (45, 80): 1, (80, 97): 1, (97, 105): 2, (105, 114): 1, (114, 32): 3, (32, 69): 1, (69, 110): 1, (110, 99): 2, (99, 111): 2, (111, 100): 3, (100, 105): 2, (105, 110): 6, (110, 103): 3, (103, 32): 3, (32, 40): 1, (40, 66): 1, (66, 80): 1, (80, 69): 1, (69, 41): 1, (41, 32): 1, (32, 119): 2, (119, 97): 1, (97, 115): 2, (115, 32): 4, (32, 105): 2, (110, 105): 3, (105, 116): 2, (116, 105): 2, (105, 97): 1, (97, 108): 2, (108, 108): 1, (108, 121): 1, (121, 32): 3, (32, 100): 1, (100, 101): 3, (101, 118): 1, (118, 101): 1, (101, 108): 3, (108, 111): 2, (111, 112): 1, (112, 101): 2, (101, 100): 3, (100, 32): 5, (32, 97): 6, (97, 110): 4, (110, 32): 4, (108, 103): 1, (103, 111): 1, (111, 114): 3, (114, 105): 1, (116, 104): 3, (104, 109): 1, (109, 32): 1, (32, 116): 5, (116, 111): 2, (111, 32): 1, (32, 99): 1, (111, 109): 1, (109, 112): 1, (112, 114): 2, (114, 101): 2, (101, 115): 1, (115, 115): 1, (101, 120): 1, (120, 116): 1, (116, 115): 1, (115, 44): 2, (44, 32): 6, (110, 100): 2, (104, 101): 3, (101, 110): 4, (32, 117): 2, (117, 115): 2, (115, 101): 2, (32, 98): 2, (98, 121): 2, (32, 79): 1, (79, 112): 1, (110, 65): 1, (65, 73): 1, (73, 32): 1, (32, 102): 1, (102, 111): 2, (111, 107): 1, (107, 101): 1, (105, 122): 1, (122, 97): 1, (97, 116): 1, (105, 111): 1, (111, 110): 1, (119, 104): 1, (32, 112): 1, (101, 116): 1, (116, 114): 1, (114, 97): 2, (101, 32): 1, (32, 71): 3, (71, 80): 3, (80, 84): 3, (84, 32): 1, (32, 109): 2, (109, 111): 2, (108, 46): 1, (46, 32): 1, (32, 73): 1, (73, 116): 1, (116, 226): 1, (226, 128): 1, (128, 153): 1, (153, 115): 1, (97, 32): 1, (32, 108): 1, (111, 116): 1, (116, 32): 1, (32, 111): 1, (111, 102): 1, (102, 32): 1, (32, 84): 1, (84, 114): 1, (110, 115): 1, (115, 102): 1, (114, 109): 1, (109, 101): 1, (101, 114): 1, (108, 115): 1, (99, 108): 1, (108, 117): 1, (117, 100): 1, (84, 44): 2, (84, 45): 1, (45, 50): 1, (50, 44): 1, (32, 82): 1, (82, 111): 1, (111, 66): 1, (66, 69): 2, (69, 82): 2, (82, 84): 3, (84, 97): 2, (97, 44): 1, (32, 66): 1, (66, 65): 1, (65, 82): 1, (32, 68): 1, (68, 101): 1, (101, 66): 1, (97, 46): 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get ordered\n",
        "print(sorted(((v,k) for k,v in stats.items()),reverse=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URu6nzckbz_2",
        "outputId": "c6775097-6984-4bd8-9e49-a054e153fc82"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(6, (105, 110)), (6, (44, 32)), (6, (32, 97)), (5, (100, 32)), (5, (32, 116)), (4, (115, 32)), (4, (110, 32)), (4, (101, 110)), (4, (97, 110)), (3, (121, 32)), (3, (116, 104)), (3, (114, 32)), (3, (111, 114)), (3, (111, 100)), (3, (110, 105)), (3, (110, 103)), (3, (104, 101)), (3, (103, 32)), (3, (101, 108)), (3, (101, 100)), (3, (100, 101)), (3, (82, 84)), (3, (80, 84)), (3, (71, 80)), (3, (32, 71)), (2, (117, 115)), (2, (116, 111)), (2, (116, 105)), (2, (116, 101)), (2, (115, 101)), (2, (115, 44)), (2, (114, 101)), (2, (114, 97)), (2, (112, 114)), (2, (112, 101)), (2, (110, 100)), (2, (110, 99)), (2, (109, 111)), (2, (108, 111)), (2, (105, 116)), (2, (102, 111)), (2, (100, 105)), (2, (99, 111)), (2, (98, 121)), (2, (97, 115)), (2, (97, 108)), (2, (97, 105)), (2, (84, 97)), (2, (84, 44)), (2, (69, 82)), (2, (66, 69)), (2, (32, 119)), (2, (32, 117)), (2, (32, 109)), (2, (32, 105)), (2, (32, 98)), (1, (226, 128)), (1, (153, 115)), (1, (128, 153)), (1, (122, 97)), (1, (121, 116)), (1, (120, 116)), (1, (119, 104)), (1, (119, 97)), (1, (118, 101)), (1, (117, 100)), (1, (116, 226)), (1, (116, 115)), (1, (116, 114)), (1, (116, 32)), (1, (115, 115)), (1, (115, 102)), (1, (114, 109)), (1, (114, 105)), (1, (111, 116)), (1, (111, 112)), (1, (111, 110)), (1, (111, 109)), (1, (111, 107)), (1, (111, 102)), (1, (111, 66)), (1, (111, 32)), (1, (110, 115)), (1, (110, 65)), (1, (109, 112)), (1, (109, 101)), (1, (109, 32)), (1, (108, 121)), (1, (108, 117)), (1, (108, 115)), (1, (108, 108)), (1, (108, 103)), (1, (108, 46)), (1, (107, 101)), (1, (105, 122)), (1, (105, 114)), (1, (105, 111)), (1, (105, 97)), (1, (104, 109)), (1, (103, 111)), (1, (102, 32)), (1, (101, 120)), (1, (101, 118)), (1, (101, 116)), (1, (101, 115)), (1, (101, 114)), (1, (101, 66)), (1, (101, 45)), (1, (101, 32)), (1, (99, 108)), (1, (97, 116)), (1, (97, 46)), (1, (97, 44)), (1, (97, 32)), (1, (84, 114)), (1, (84, 45)), (1, (84, 32)), (1, (82, 111)), (1, (80, 97)), (1, (80, 69)), (1, (79, 112)), (1, (73, 116)), (1, (73, 32)), (1, (69, 110)), (1, (69, 41)), (1, (68, 101)), (1, (66, 121)), (1, (66, 80)), (1, (66, 65)), (1, (65, 82)), (1, (65, 73)), (1, (50, 44)), (1, (46, 32)), (1, (45, 80)), (1, (45, 50)), (1, (41, 32)), (1, (40, 66)), (1, (32, 112)), (1, (32, 111)), (1, (32, 108)), (1, (32, 102)), (1, (32, 100)), (1, (32, 99)), (1, (32, 84)), (1, (32, 82)), (1, (32, 79)), (1, (32, 73)), (1, (32, 69)), (1, (32, 68)), (1, (32, 66)), (1, (32, 40))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Most common pair key value\n",
        "topPair= max(stats,key=stats.get)\n",
        "chr(topPair[0]), chr(topPair[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mbtlopDcSQi",
        "outputId": "ee3f22f9-ac5b-4138-cda9-b0812c59237f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('i', 'n')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def merge(ids,pair,idx):\n",
        "  # The list of ints (ids), replace all consecutive occurences of pair with the new token idx\n",
        "  newids=[]\n",
        "  i=0\n",
        "  while i < len(ids):\n",
        "    if i < len(ids) - 1 and ids[i] == pair[0] and ids[i+1] == pair[1]:\n",
        "      newids.append(idx)\n",
        "      i+=2\n",
        "    else:\n",
        "      newids.append(ids[i])\n",
        "      i+=1\n",
        "  return newids\n",
        "\n",
        "print(merge([5,6,6,7,9,1],(6,7),99))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwTuHglylBiO",
        "outputId": "382d4396-79c5-433e-975f-1777e4b77eaf"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5, 6, 99, 9, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens2 = merge(tokens,topPair,255) ## For test purposes I'm merging the top pair token into 255\n",
        "print(tokens2)\n",
        "print(f\"Length: {len(tokens2)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_aslXzKmZfX",
        "outputId": "6bbce51d-b07a-4e73-994b-bdd3af586bd0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[66, 121, 116, 101, 45, 80, 97, 105, 114, 32, 69, 110, 99, 111, 100, 255, 103, 32, 40, 66, 80, 69, 41, 32, 119, 97, 115, 32, 255, 105, 116, 105, 97, 108, 108, 121, 32, 100, 101, 118, 101, 108, 111, 112, 101, 100, 32, 97, 115, 32, 97, 110, 32, 97, 108, 103, 111, 114, 105, 116, 104, 109, 32, 116, 111, 32, 99, 111, 109, 112, 114, 101, 115, 115, 32, 116, 101, 120, 116, 115, 44, 32, 97, 110, 100, 32, 116, 104, 101, 110, 32, 117, 115, 101, 100, 32, 98, 121, 32, 79, 112, 101, 110, 65, 73, 32, 102, 111, 114, 32, 116, 111, 107, 101, 110, 105, 122, 97, 116, 105, 111, 110, 32, 119, 104, 101, 110, 32, 112, 114, 101, 116, 114, 97, 255, 255, 103, 32, 116, 104, 101, 32, 71, 80, 84, 32, 109, 111, 100, 101, 108, 46, 32, 73, 116, 226, 128, 153, 115, 32, 117, 115, 101, 100, 32, 98, 121, 32, 97, 32, 108, 111, 116, 32, 111, 102, 32, 84, 114, 97, 110, 115, 102, 111, 114, 109, 101, 114, 32, 109, 111, 100, 101, 108, 115, 44, 32, 255, 99, 108, 117, 100, 255, 103, 32, 71, 80, 84, 44, 32, 71, 80, 84, 45, 50, 44, 32, 82, 111, 66, 69, 82, 84, 97, 44, 32, 66, 65, 82, 84, 44, 32, 97, 110, 100, 32, 68, 101, 66, 69, 82, 84, 97, 46]\n",
            "Length: 244\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Construct a forest of tokens"
      ],
      "metadata": {
        "id": "8M4uG9Z5oBqZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 276\n",
        "num_merges = vocab_size - 256 ## Merge 20 times each individual byte pair -> token\n",
        "ids = list(tokens)\n",
        "\n",
        "merges = {}\n",
        "for i in range(num_merges):\n",
        "  stats = get_stats(ids)\n",
        "  pair = max(stats,key=stats.get)\n",
        "  idx = 256 + i\n",
        "  print(f\"Merging {pair} into a new token {idx}\")\n",
        "  ids = merge(ids,pair,idx)\n",
        "  merges[pair]=idx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQFeLuhzmzuT",
        "outputId": "889418ce-0ae9-494e-ee73-3c98ebc61af4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Merging (105, 110) into a new token 256\n",
            "Merging (32, 97) into a new token 257\n",
            "Merging (32, 116) into a new token 258\n",
            "Merging (101, 110) into a new token 259\n",
            "Merging (44, 32) into a new token 260\n",
            "Merging (111, 100) into a new token 261\n",
            "Merging (256, 103) into a new token 262\n",
            "Merging (101, 108) into a new token 263\n",
            "Merging (101, 100) into a new token 264\n",
            "Merging (257, 110) into a new token 265\n",
            "Merging (111, 114) into a new token 266\n",
            "Merging (71, 80) into a new token 267\n",
            "Merging (267, 84) into a new token 268\n",
            "Merging (82, 84) into a new token 269\n",
            "Merging (114, 32) into a new token 270\n",
            "Merging (262, 32) into a new token 271\n",
            "Merging (32, 119) into a new token 272\n",
            "Merging (115, 32) into a new token 273\n",
            "Merging (105, 116) into a new token 274\n",
            "Merging (121, 32) into a new token 275\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"tokens length: \",len(tokens))\n",
        "print(\"ids length: \", len(ids))\n",
        "print(f\"Compression ratio: {len(tokens)/len(ids):.2f}X\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SK6HCrK3oXZC",
        "outputId": "ccc238e0-7ef7-40aa-e657-c4579343983c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tokens length:  250\n",
            "ids length:  186\n",
            "Compression ratio: 1.34X\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decoding\n",
        "Given a sequence of integers in the range [0,vocab_size] what is the text?"
      ],
      "metadata": {
        "id": "dEBAdtz-Mgoq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = {idx:bytes([idx]) for idx in range(256)}\n",
        "\n",
        "for (p0,p1), idx in merges.items():\n",
        "  vocab[idx]= vocab[p0] + vocab[p1]\n",
        "\n",
        "def decode(ids):\n",
        "  # Given ids (list of integers), return Python string\n",
        "  tokens = b\"\".join(vocab[idx] for idx in ids)\n",
        "  text= tokens.decode(\"utf-8\",errors=\"replace\")\n",
        "  return text\n",
        "\n",
        "\n",
        "def encode(text):\n",
        "  tokens = list(text.encode(\"utf-8\"))\n",
        "  while len(tokens) >= 2:\n",
        "    stats = get_stats(tokens)\n",
        "    pair = min(stats,key= lambda p:merges.get(p,float(\"inf\")))\n",
        "    if pair not in merges:\n",
        "      break # nothing else can be merged\n",
        "    idx = merges[pair]\n",
        "    tokens = merge(tokens,pair,idx)\n",
        "  return tokens\n",
        "\n",
        "print(encode(\"hello world!\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXjV11K2Mmg6",
        "outputId": "4e7bcf3b-3755-4585-bfe6-d309c9db5a83"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[104, 263, 108, 111, 272, 266, 108, 100, 33]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wlnqRUGwb29n"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}